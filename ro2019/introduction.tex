\section{Introduction}

\textbf{Reproducibility in science.}

Modern science is founded on the expectation that the observations, experiments, and
	predictions that comprise scientific research be independently verifiable by others.
This requirement, referred to either as the \emph{reproducibility} of 
	science, applies not only to the products of research studies (\emph{results}, 
	\emph{conclusions}, \emph{models}, \emph{data products}, \emph{predictions}), but also to the 
	activities comprising a study that ultimately give rise to these products (\emph{methods}, 
	\emph{protocols}, \emph{workflows}); the materials employed in these 
	research actitivties (\emph{reagents}, \emph{instruments}, \emph{software}); and the conditions 
	under which which these activities are carried out (\emph{instrument settings}, \emph{software parameters},
	\emph{computing environments}).  When sufficient details are available
	such that the research products and methods can be reviewed, interpreted, and
	evaluated by other researchers \emph{without} repeating the work, a study is said to be 
	\emph{transparent}.

While it is true that studies attempting primarily to reproduce previous results are relatively rare in the
	natural sciences, even the most groundbreaking studies in these fields include components	
	that explicitly or implicitly confirm the reproducibility of previous results and reported procedures.
The expectation is that new studies will reliably produce meaningful results consistent with previous work 
	only if the prior work on which it is based or relates to is reproducible.
In this sense, the whole of basic research in the natural sciences can be seen as an ongoing, massively-parallel
	reproducibility study that also happens to produce new results.
Exceptions to this pattern occur when studies appear to overturn well-established understandings of nature,
	violate the expectations of how research in a particular field is to be carried out, or otherwise cause controversy.
In these cases direct attempt may be made to reproduce results by precisely replicating the reported methods
	and conditions reported in the controversial study.


\textbf{Limits on exact repeatability.}

Even when attempts are made to confirm the reproducibility of particular studies or results, investigators in
	the natural sciences generally do not expect the products of research to be repeated exactly.
The vast majority of quantitative observations made of real world phenonema using scientific instruments
	are associated with limited precision and other intrinsic uncertainties that must themselves be characterized
	and well understood for science baed on them to be reproducible.
It is a hallmark of trustworthy science that quantitative observations and claims be inseparable from the uncertainty
	in the reported values ultimately deriving from these uncertainties in measurement and the resulting
	propagation of errors through data analysis.

In contrast, digital computing approaches make it possible to repeat exactly certain computational aspects of research
	to an extent that exceeds what can be achieved when observing natural sphenomena in the physical world.  
It generally is expected that computational processes, the implementation of hardware and software 
	enabling those processes, and the outputs of those processes all can be repeated exactly--at least in principle.
Where computing makes up a significant fraction of scientific research, there is a risk that the longstanding
	understanding of reproducibility in in the sciences can be conflated with this new, radically different 
	expectation of exact repeatability. 

Moreover, while exact repeatability of computational experiments and analyses may be realizable in principle, 
	in practice the complexities of real-world hardware and software make computational repeatability 
	very challenging to achieve in practice except in very limited cases.
Currently much effort is going into expanding the fraction of scenarios in which the computational
	components of research can be automatically repeated exactly over ranges of time and space relevant to scientific 
	research and discourse.
These efforts are important for the research community to pursue, and for science funding
	agencies to support, especially because the computing industry generally does not have 
	requirements for exact repeatability across signficant spans of time.
However, it also is crucial to note that the concept of exact repeatability of the kind pursued by these efforts is 
	qualitatively different from the concept of reproducibility that underlies the natural sciences.
It is even more important to realize that scientific reproducibility is not simply a weaker form of computational
	repeatability.  
Achieving computational repeatability does not automatically deliver scientific reproducibility.


\textbf{Reproducibility by other means.}

It is both bad and good news that exact, computational repeatability is not tantamount to reprodubility.
The bad news is that it is possible to put much effort into achieving computational repeatability without delivering
	the kind of reproducibility that is critical for producing trustworthy science.
The good news is that scientifically-meaningful reproducibility can be realized in cases (or over spans of time)
	where computational repeatability is either impossible or impractical given readily available technology.
In this paper we propose that the older concept of reproducibility of that permeates the natural sciences has a very
	useful role to even where digital computing makes exact repeatability a theoretical possibility.

 Reseachers in the natural sciences are comfortable with the idea that it is not possible to exactly
	repeat all reported observations, procedures, and experimental results.
They do not see this concession to real-world practicalities as a contradiction to their demand that science be reproducible.
What the natural sciences actually do demand is that 
	(a) research procedures be repeatable by others in principle.
	(b) The means of repeating the work be subject to review and evaluation.  
	(c) Such review and evaluation be possible without actually repeating the work.
	And that (d) it not be required to repeat the exacts taken in reported research to reproduce results.

To be clear, in the natural sciences it is actually considered a \emph{problem} if exact repetition of the steps
	taken in reported research is required either to evaluate the work or to reproduce results.

The reason this is good news for computation-intensive research is that it is not necessary to achieve or 
	maintain perfect repeatability of the computational components of research in order for scientists to 
	consider the work reproducible and therefore trustworthy.
However, this also means that the standards, technologies, and computational best-practices that we develop and advocate
	in fact support scientific reproducibility.
Pursuing and supporting exact computational repeatedly is not enough.
In this paper we argue that the necessary ingredient of reproducible research most at risk of left out when supporting computational
	repeatability is transparency.
We emphasisze that an area in which computer science has much to offer in supporting transparency is in the modeling, recording, 
	and querying of the provenance of research artifacts.
But we also point out that for provenance to support reprodudibility it must support science-oriented queries.
Provenance must be able to answer questions about the science that was performed--not just the computations.
Answers to these questions must enable others to evaluate the scientific quality of the work, and to learn what is necessary to 
	reproduce the results without blindly repeating every step taken in the original work.
And we suggest that Research Objects and related approaches are the ideal vehicle for storing and make provenance queryable
	in this way, thus supporting true scientific reproducibility.