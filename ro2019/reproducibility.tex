\section{Reproducibility in science}

Modern science is founded on the expectation that the observations, experiments, and
	predictions that comprise scientific research be independently verifiable by others.
This requirement, referred to as the \emph{reproducibility} or \emph{replicability} of 
	science, applies not only to the products of research studies (\emph{substances}, 
	\emph{results}, \emph{conclusions}, \emph{models}, \emph{data products}, 
	\emph{predictions}), but also to the activities that ultimately give rise to these
	products (\emph{methods}, \emph{protocols}, \emph{workflows}); the materials 
	employed in these activities (\emph{reagents}, \emph{instruments}, 
	\emph{software}); and the conditions 
	under which which these activities are carried out (\emph{temperatures},
	\emph{instrument settings}, \emph{software parameters},
	\emph{computing environments}).  When sufficient details are available
	such that the research products and methods can be reviewed, interpreted, and
	evaluated by other researchers \emph{without} repeating the work, a study is said to be 
	\emph{transparent}.

While it is true that studies attempting primarily to reproduce previous results are relatively rare in the
	pure natural sciences, even the most groundbreaking studies in these fields include components	
	that explicitly or implicitly confirm the reproducibility of previously reported results and procedures.
The expectation is that new studies will reliably produce meaningful results consistent with previous work 
	only if the prior work on which they are based or otherwise relates to is reproducible.
In this sense, the whole of basic research in the natural sciences can be seen as an ongoing, massively-parallel
	reproducibility study that also happens to produce a steady stream of new results.
Exceptions to this pattern occur when studies appear to overturn well-established understandings of nature,
	violate the expectations of how research in a particular field is to be carried out, or otherwise cause controversy.
In these cases direct attempts may be made to reproduce results by duplicating as carefully as possible
	the reported methods and conditions described in the controversial study.

Even when attempts are made specifically to confirm the reproducibility of particular studies or results, investigators in
	the natural sciences generally do not expect the processes and products of research to be duplicated exactly.
The vast majority of quantitative observations made of real world phenomena using scientific instruments
	are associated with limited precision and other intrinsic uncertainties that must themselves be characterized
	and well understood for science based on them to be considered reproducible.
It is a hallmark of trustworthy science that quantitative observations and claims are inseparable from these 
	uncertainties in measurement and their propagation through data analysis.

Similarly, the materials and processes employed in the natural sciences generally are impossible
	to duplicate exactly.
In a chemistry laboratory, the precise quantities of input reagents will vary, temperatures will differ, and heating
	or cooling rates will be unique for each run of a chemical synthesis, no matter how carefully these conditions
	are controlled; the yield and purity of the intended product necessarily will vary as well from run to run.
A similar situation holds when measurements are made on samples using a scientific instrument. 
Different instruments of the same model will vary slightly and produce slightly different results even
	under identical conditions on identical samples.
Generally, the original researchers are in the best position to assess how the minimum variation expected
	between runs of a synthesis (they have access to the same batch of reagents and the same equipment), 
	or between repeated readings of an instrument on the same or equivalent samples (they can prepare
	multiple samples at the same time, and run these samples through the instrument one after the other).
A researcher attempting to duplicate another's work can expect to see greater deviation from the reported results	
	because the materials and conditions involved will necessarily differ to a greater degree.

This asymmetry between the original researcher and another repeating the work is reflected in the longstanding
	distinction between \emph{reproducibility} and \emph{replicability} in experimental biology.  
In Section 4 we will examine definitions of these terms jointly adopted by twenty-nine research
	societies in the biological sciences.  
For now we note that the notion of \emph{replicates}, repeated measurements made to quantify 
	experimental variability, is represented by a rich literature.
This literature distinguishes between distinct modes of experimental replication.
The term \emph{technical replicates}, for example, refers to repeated measurements performed on the same sample.
These are used to assess the variation intrinsic to the procedure, apparatus, and instrument employed.
\emph{Biological replicates} represent measurements made on different but equivalent samples.
In practice both generally are performed by the original researcher under conditions otherwise
	held as constant as possible.

FOOTNOTE: Generating multiple gigabytes of raw data requiring intensive computational analysis for each replicate, 
	Next-Generation Sequencing (NGS) represent just one sub-domain where the reproducibility 
	terminologies in the natural sciences and in computing unavoidably collide.

In contrast, digital computing approaches make it possible to repeat \emph{exactly} certain computational aspects of research,
	 even by \emph{different} researchers using \emph{different} computers.  
Indeed, it generally is expected that computational processes, the implementation of hardware and software 
	enabling those processes, and the outputs of those processes all can be repeated exactly by others--at least in principle.
This potential of exact repeatability is unquestionably of enormous value to any field of research employing computers,
	and certainly will contribute to the ability of researchers in every field to reproduce or build on others' work.
At the same time, there is at least some risk of this new expectation of exact repeatability being conflated 
	(consciously or unconsciously) with the longstanding understanding of reproducibility in the basic sciences. 
It is essential that the new concept be kept distinct.

Moreover, while computational experiments and analyses may be exactly repeatable in principle, 
	in practice the complexities of real-world hardware and software currently make computational repeatability 
	challenging to achieve in practice except over very limited time scales.
Because of the obvious value that exact repeatability brings when it is feasible, it is important that we work to
	expand the fraction of scenarios in which the computational components of research can be automatically 
	repeated exactly over ranges of time and space relevant to scientific research and discourse.
These efforts are particularly important for the research community to pursue, and for science funding
	agencies to support, because the computing industry generally does not have requirements for exact 
	repeatability across significant spans of time.

Again---it is important to acknowledge that the concept of exact repeatability is 
	qualitatively different from the concept of reproducibility that underlies the natural sciences.
In particular, scientific reproducibility is not simply a weaker form of computational repeatability.  
\emph{Approximating or achieving computational repeatability does not automatically deliver scientific reproducibility.}

It is in a sense both bad and good news that exact computational repeatability is not tantamount to scientific reproducibility.
The disappointing news, perhaps, is that it is possible to put much effort into achieving computational repeatability,
	exact where practical and inexact otherwise,
	without delivering the kind of reproducibility that is critical for producing trustworthy science.
The good news is that scientifically meaningful reproducibility can be realized in cases (or over spans of time)
	where computational repeatability is impractical due to the limitations of available technology or affordable resources.
Thus, the older concept of reproducibility that permeates the basic natural sciences has a very
	useful role even where digital computing makes exact repeatability a theoretical possibility.

 Researchers in the natural sciences are comfortable with the idea that it is not possible to exactly
	repeat all reported observations, procedures, and experimental results.
They do not see this as a contradiction to their demand that science be reproducible.
What the natural sciences actually do demand is that 
	(a) research procedures be repeatable by others in principle;
	(b) the means of repeating the work be subject to review and evaluation; 
	and (c) such review and evaluation be possible \emph{without} actually repeating the work.
To be perfectly clear about the third demand: in the natural sciences it is actually considered a 
	\emph{problem} if exact repetition of the steps taken in reported research is required either
	to evaluate the work or to reproduce results.

Consequently, it is not necessary to achieve or 
	maintain perfect repeatability of the computational components of research for scientists to 
	consider a study reproducible and therefore trustworthy.
At the same time it is important that the standards, technologies, 
	computational best-practices, and infrastructure we develop and advocate in fact support scientific reproducibility.
It is not enough, in the long run, to pursue and support exact computational repeatability where we can, 
	and to get as close as possible otherwise.
Rather, computational repeatability is best seen as a dimension of research reproducibility \emph{orthogonal} to 
	the dimension of transparency.
It is possible to achieve computational repeatability without providing research transparency---and vice versa.
Moreover, exact repeatability is not an essential element of scientific reproducibility in the broadest sense of the term.
Transparency arguably is.
