\section{Reproducibility Queries}\label{sec-transparency}

Research Objects from the beginning have been advocated as vehicles for sharing the 
	provenance of scientific results and data products.
Whole Tale currently is turning its attention to provenance capabilities, placing particular
	focus on leveraging provenance management techniques and technologies
	to enhance the reproducibility and transparency of Tales.
Here we point list just a few of the ways we see our prior work in the area
	of science-oriented provenance queries contributing to this effort in Whole Tale,
	and to enhancing reproducibility and transparency in Research Objects generally.

For provenance management systems, representations, and user interfaces to support 
	reproducibility via transparency, they must support \emph{science-oriented queries}.
Provenance must be able to answer questions about the \emph{science} that was performed---not just the
	sequence, dependencies, and flow of data through computational steps.
The answers to these questions must enable others to evaluate the scientific quality of the work, 
	and to learn what is necessary to
	reproduce the results \emph{without} actually repeating every step taken in the original work.
Provenance is to enabling researchers to build on computed results reported in prior work with confidence.

In [TM2015] we provided a number of example queries about a run of a scientific
	workflows implemented in Python and annotated using YesWorkflow.
Answers to these queries revealed the dependencies of particular workflow outputs
	on the input samples, parameter values, and intermediate data.
The queries were phrased in terms familiar to researchers  in the example domain
	and demonstrated how provenance queries can be used by scientists
	to answering scientific questions about the research.

We plan to extend this approach of enabling researchers to pose science-oriented
	provenance queries to Research Objects that support the other capabilities
	described in this paper.
Such queries would allow a researcher to determine not just that a study as a whole
	is FASEB::reproducible, for example, but also that is a particular result
	is NAS:reproducible (which is a completely different thing).
For studies that do not qualify as FASEB::reproducible as a whole, researchers
	could discover which results are in fact FASEB::replicable.
Where a particular results is not FASEB::replicable, they could pose a query
	that reveals what part of the method that produced the result is 
	not replicable.
Answers to such queries could take available technology for reproducing computations
	into account.
For example, a particular result might no longer be NAS::reproducible using the
	latest version of Docker.

Finally, it must be possible for researchers unversed in the detailed
	specifications of Research Objects and the PROV
	standard~\cite{groth2013provoverviewa} to pose questions and receive
	answers meaningful for evaluating, using, and building on the
	processes and products of prior research. 
By combining capabilities for querying transitive data dependencies with 
	approaches we proposed for precisely characterizing the reproducibility of computed
	results and data products, we expect to bring the computational components
	closer to the level of reproducibility that characterizes the natural sciences.
It would be clear what studies are reproducible and what methods underlying reproducible
	results can be used in future studies.
Research Objects that are transparent in this sense would allow researchers to build 
	on each others work with greater confidence---without 
	actually having to rerun another researcher's study.
This is reproducibility by other means.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
